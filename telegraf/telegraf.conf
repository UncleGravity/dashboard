# [global_tags]
#   env = "prod"

[agent]
  interval = "15s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = ""
  hostname = ""
  omit_hostname = false

###############################################################################
#                            INPUTS                                           #
###############################################################################
# [[inputs.diskio]]
[[inputs.system]]
  fieldpass = ["uptime"]

[[inputs.cpu]]
  taginclude = ["cpu"]
  fieldpass = ["usage_active", "usage_idle", "total", "used_percent"]

  ## Whether to report per-cpu stats or not
  percpu = true
  ## Whether to report total system cpu stats or not
  totalcpu = true
  ## If true, collect raw CPU time metrics
  collect_cpu_time = false
  ## If true, compute and report the sum of all non-idle CPU states
  report_active = true
  ## If true and the info is available then add core_id and physical_id tags
  core_tags = false

[[inputs.mem]]
  fieldpass = ["total", "available", "available_percent", "swap_cached", "swap_free", "swap_total"]


[[inputs.disk]]
  taginclude= ["device", "path"]
  fieldpass = ["used", "total", "used_percent"]
  ## By default stats will be gathered for all mount points.
  ## Set mount_points will restrict the stats to only the specified mount points.
  # mount_points = ["/"]

  ## Ignore mount points by filesystem type.
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

  ## Ignore mount points by mount options.
  ## The 'mount' command reports options of all mounts in parathesis.
  ## Bind mounts can be ignored with the special 'bind' option.
  # ignore_mount_opts = []

  # Gather metrics about network interfaces
[[inputs.net]]
  taginclude = ["interface"]
  fieldpass = ["bytes_recv", "bytes_sent"]
  ## By default, telegraf gathers stats from any up interface (excluding loopback)
  ## Setting interfaces will tell it to gather these explicit interfaces,
  ## regardless of status. When specifying an interface, glob-style
  ## patterns are also supported.
  ##
  interfaces = ["eth*", "enp0s*", "lo"]
    # interfaces = ["enp0s5"]
  ##
  ## On linux systems telegraf also collects protocol stats.
  ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
  ##
  # ignore_protocol_stats = false
  ##

[[inputs.docker]]
  namedrop = ["docker_container_health", "docker_container_status", "docker_container_blkio"]
  # tagexclude = ["com.*"]
  taginclude = [
    "container_name", "container_status", # common
    "cpu", # cpu
    "network", # net
    ]
  fieldpass = [
    "n_containers", "n_containers_running", # docker
    "usage_percent", # cpu
    "limit", "usage", "usage_percent", # mem
    "rx_bytes", "tx_bytes" # net
  ]
  endpoint = "unix:///var/run/docker.sock"
  gather_services = false
  source_tag = false
  container_name_include = []
  container_name_exclude = []
  timeout = "5s"
  total = false
  docker_label_include = []
  docker_label_exclude = []
  tag_env = ["JAVA_HOME", "HEAP_SIZE"]

###############################################################################
#                            OUTPUTS                                          #
###############################################################################

# [[outputs.file]]
#   files = ["stdout"]

# Publishes metrics to a postgresql database
[[outputs.postgresql]]
  ## Specify connection address via the standard libpq connection string:
  ##   host=... user=... password=... sslmode=... dbname=...
  ## Or a URL:
  ##   postgres://[user[:password]]@localhost[/dbname]?sslmode=[disable|verify-ca|verify-full]
  ## See https://www.postgresql.org/docs/current/libpq-connect.html#LIBPQ-CONNSTRING
  ##
  ## All connection parameters are optional. Environment vars are also supported.
  ## e.g. PGPASSWORD, PGHOST, PGUSER, PGDATABASE
  ## All supported vars can be found here:
  ##  https://www.postgresql.org/docs/current/libpq-envars.html
  ##
  ## Non-standard parameters:
  ##   pool_max_conns (default: 1) - Maximum size of connection pool for parallel (per-batch per-table) inserts.
  ##   pool_min_conns (default: 0) - Minimum size of connection pool.
  ##   pool_max_conn_lifetime (default: 0s) - Maximum age of a connection before closing.
  ##   pool_max_conn_idle_time (default: 0s) - Maximum idle time of a connection before closing.
  ##   pool_health_check_period (default: 0s) - Duration between health checks on idle connections.
  # connection = "host=timescaledb:5432 user=postgres password=rouwqig2e62W4CqRcBem dbname=postgres"
  connection = "postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:${POSTGRES_PORT}/${POSTGRES_DB}?sslmode=disable"

  ## Postgres schema to use.
  schema = "telegraf"

  ## Store tags as foreign keys in the metrics table. Default is false.
  # tags_as_foreign_keys = false

  ## Suffix to append to table name (measurement name) for the foreign tag table.
  # tag_table_suffix = "_tag"

  ## Deny inserting metrics if the foreign tag can't be inserted.
  # foreign_tag_constraint = false

  ## Store all tags as a JSONB object in a single 'tags' column.
  # tags_as_jsonb = false

  ## Store all fields as a JSONB object in a single 'fields' column.
  # fields_as_jsonb = false

  # # Templated statements to execute when creating a new table.
  # create_templates = [
  #   '''CREATE TABLE {{ .table }} ({{ .columns }})''',
  # ]

  create_templates = [
    '''CREATE TABLE {{ .table }} ({{ .columns }})''',
    '''ALTER TABLE {{ .table }} ALTER COLUMN time TYPE timestamp with time zone''',
    '''SELECT create_hypertable({{ .table|quoteLiteral }}, 'time')''',
    # '''ALTER TABLE {{ .table }} SET (timescaledb.compress, timescaledb.compress_segmentby = 'tag_id')''',
    '''SELECT add_retention_policy({{ .table|quoteLiteral }}, INTERVAL '7 days')'''
  ]

  # # Templated statements to execute when adding columns to a table.
  # # Set to an empty list to disable. Points containing tags for which there is no column will be skipped. Points
  # # containing fields for which there is no column will have the field omitted.
  # add_column_templates = [
  #   '''ALTER TABLE {{ .table }} ADD COLUMN IF NOT EXISTS {{ .columns|join ", ADD COLUMN IF NOT EXISTS " }}''',
  # ]

  # # Templated statements to execute when creating a new tag table.
  # tag_table_create_templates = [
  #   '''CREATE TABLE {{ .table }} ({{ .columns }}, PRIMARY KEY (tag_id))''',
  # ]

  # # Templated statements to execute when adding columns to a tag table.
  # # Set to an empty list to disable. Points containing tags for which there is no column will be skipped.
  # tag_table_add_column_templates = [
  #   '''ALTER TABLE {{ .table }} ADD COLUMN IF NOT EXISTS {{ .columns|join ", ADD COLUMN IF NOT EXISTS " }}''',
  # ]

  # The postgres data type to use for storing unsigned 64-bit integer values (Postgres does not have a native
  # unsigned 64-bit integer type).
  # The value can be one of:
  #   numeric - Uses the PostgreSQL "numeric" data type.
  #   uint8 - Requires pguint extension (https://github.com/petere/pguint)
  uint64_type = "numeric"

  ## When using pool_max_conns>1, and a temporary error occurs, the query is retried with an incremental backoff. This
  ## controls the maximum backoff duration.
  # retry_max_backoff = "15s"

  ## Approximate number of tag IDs to store in in-memory cache (when using tags_as_foreign_keys).
  ## This is an optimization to skip inserting known tag IDs.
  ## Each entry consumes approximately 34 bytes of memory.
  # tag_cache_size = 100000

  ## Enable & set the log level for the Postgres driver.
  # log_level = "warn" # trace, debug, info, warn, error, none

